---
layout: post
title: The Raise of AI
author: Călin
---

## Disclaimer

## Issues

- the models have gotten so good that lots of people believe them -- without any filtering. GPT-4 papers.
- consciousness: are these models sentient? Blaise's [Economist](https://www.economist.com/by-invitation/2022/06/09/artificial-neural-networks-are-making-strides-towards-consciousness-according-to-blaise-aguera-y-arcas) and [Medium post](https://medium.com/@blaisea/can-machines-learn-how-to-behave-42a02a57fadb) vs. [ChatGPT Is a Blurry JPEG of the Web](https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web).
- Bender's argument vs. the bearded man in the audience: [You are not a parrot](https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html). What is the difference between a hallucinating model and Trump's claim that "words do not count"?
- what does it mean to be responsible when people are as gullible as they are? ChatGPT task rabbit example.

  - [Why ChatGPT should be considered a malevolent AI – and be destroyed](https://www.theregister.com/2023/03/02/chatgpt_considered_harmful/)
  -
  -
## Actions

 - activism: the [open letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)
 - tech: explainable models, alignment, responsible AI
 - government regulation? I don't think so! It is useful to signal the need for boundaries, but those boundaries need first to be understood by the people who are developing these tools (and we're very far from it) and built into the tools in an enforceable way.
- ACM authorship policy on AI generated content.

